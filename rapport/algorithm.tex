\section{Presented algorithm}

The goal of the algorithm presented in this article is to learn the dynamics of the system, which means to learn the functions $f$ and $g$  and the noise covariance matrices $Q$ and $R$ that are supposed to be unknown.
The functions $f$ and $g$ are parametrized by $\theta_f$ and $\theta_g$.

So our dynamical system is parametrized by $\theta = \left(\theta_f, \theta_g, Q, R \right)$ and we want to learn the value of $\theta$ with the maximum likelihood principle.

The complication is that both the parameter $\theta$ and the state sequence $(x_t)_{t=1 \cdots T}$ are unknown.
In such case where both states and parameters are unknown, a typical approach is to use an iterative Expectations Maximization (EM) algorithm:
\begin{itemize}
  \item we begin with initial values for the parameter $\theta^{(0)} = \left( \theta_f^{(0)}, \theta_g^{(0)}, Q^{(0)}, R^{(0)} \right)$.
\item For $k=1 \ldots K$, we iterate E-step and M-step:
  \begin{itemize}
    %\item In the \textbf{E-step}, the states \notes{Plut√¥t les marginales conditionnelles des states non ? $ p(x_t | y_1,\ldots,y_T, U)$} $(x_t)_{t=1 \cdots T}$ are inferred (or estimated) knowing the parameter $\theta^{(k-1)} = \left( \theta_f^{(k-1)}, \theta_g^{(k-1)}), Q^{(k-1)}, R^{(k-1)} \right)$ computed in the previous M-Step. The article propose to use a Kalman Smoother. \notes{Ici il faudra en dire plus, sinon on ne fait que repeter le cours}

    \item The \textbf{E-step} consists in a \textit{smoothing} problem, where we want to infer \\ $p(x_t | y_1,\ldots,y_T, u_1,\ldots,u_T)$, the distributions of the states knowing observations $y$ and inputs $u$.
      To that end, the article propose to use an Extended Kalman Smoother, in order to account for the non-linearity of the dynamic.
    \item In the \textbf{M-step}, the updated parameter $\theta^{(k)} = \left( \theta_f^{(k)}, \theta_g^{(k)}, Q^{(k)}, R^{(k)} \right)$ is computed thanks to the states $(x_t)_{t=1 \cdots T}$ inferred in the E-Step.
  \end{itemize}
\end{itemize}
